{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "\n",
    "# load in TF-IDF vector file\n",
    "tfidf_vectors = pd.read_excel('tdf-vectors.xlsx', index_col=0)\n",
    "\n",
    "tfidf_vectors.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce dataframe to only contain initial centroids and 3  additional vectors of each article topic \n",
    "# (and the terms for now, but we will drop those)\n",
    "\n",
    "tfidf_vectors = tfidf_vectors[['9901_sports.txt-tfidf','0101_sports.txt-tfidf','0102_sports.txt-tfidf','0103_sports.txt-tfidf',\n",
    "               '9902_food.txt-tfidf','0105_food.txt-tfidf','0110_food.txt-tfidf','0201_food.txt-tfidf',\n",
    "               '9903_tech.txt-tfidf','0305_tech.txt-tfidf','0420_tech.txt-tfidf','0312_tech.txt-tfidf',\n",
    "               '9904_science.txt-tfidf','0310_science.txt-tfidf','0409_science.txt-tfidf','0419_science.txt-tfidf',\n",
    "               '9905_business.txt-tfidf','0519_business.txt-tfidf','0501_business.txt-tfidf','0518_business.txt-tfidf',\n",
    "               '9906_politics.txt-tfidf','0515_politics.txt-tfidf','0505_politics.txt-tfidf','0520_politics.txt-tfidf']]\n",
    "\n",
    "tfidf_vectors = tfidf_vectors.reindex(sorted(tfidf_vectors.columns), axis=1)\n",
    "\n",
    "tfidf_vectors\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectors['sports_centroid'] = tfidf_vectors['9901_sports.txt-tfidf']\n",
    "tfidf_vectors['food_centroid'] = tfidf_vectors['9902_food.txt-tfidf']\n",
    "tfidf_vectors['tech_centroid'] = tfidf_vectors['9903_tech.txt-tfidf']\n",
    "tfidf_vectors['science_centroid'] = tfidf_vectors['9904_science.txt-tfidf']\n",
    "tfidf_vectors['business_centroid'] = tfidf_vectors['9905_business.txt-tfidf']\n",
    "tfidf_vectors['politics_centroid'] = tfidf_vectors['9906_politics.txt-tfidf']\n",
    "\n",
    "tfidf_vectors\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_matrix = pd.DataFrame(columns=['sports_centroid','food_centroid','tech_centroid','science_centroid','business_centroid','politics_centroid'])\n",
    "\n",
    "# import package\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "for col in tfidf_vectors.columns:\n",
    "    if 'tfidf' in str(col):\n",
    "        idx = str(col)\n",
    "        sports_dist = round(cosine(tfidf_vectors[col], tfidf_vectors['sports_centroid']),10)\n",
    "        food_dist = round(cosine(tfidf_vectors[col], tfidf_vectors['food_centroid']),10)\n",
    "        tech_dist = round(cosine(tfidf_vectors[col], tfidf_vectors['tech_centroid']),10)\n",
    "        science_dist = round(cosine(tfidf_vectors[col], tfidf_vectors['science_centroid']),10)\n",
    "        business_dist = round(cosine(tfidf_vectors[col], tfidf_vectors['business_centroid']),10)\n",
    "        politics_dist = round(cosine(tfidf_vectors[col], tfidf_vectors['politics_centroid']),10)\n",
    "        \n",
    "        distance_matrix.loc[idx] = [sports_dist, food_dist, tech_dist, science_dist, business_dist, politics_dist]\n",
    "        \n",
    "distance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_matrix.idxmax(axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sports_cluster = []\n",
    "food_cluster = []\n",
    "tech_cluster = []\n",
    "science_cluster = []\n",
    "business_cluster = []\n",
    "politics_cluster = []\n",
    "\n",
    "for doc in distance_matrix.index:\n",
    "    \n",
    "    centroid = distance_matrix.loc[doc].idxmin()\n",
    "    \n",
    "    if 'sports' in str(centroid):\n",
    "        sports_cluster.append(str(doc))\n",
    "    \n",
    "    if 'food' in str(centroid):\n",
    "        food_cluster.append(str(doc))\n",
    "        \n",
    "    if 'tech' in str(centroid):\n",
    "        tech_cluster.append(str(doc))\n",
    "        \n",
    "    if 'science' in str(centroid):  \n",
    "        science_cluster.append(str(doc))\n",
    "        \n",
    "    if 'business' in str(centroid):\n",
    "        business_cluster.append(str(doc))\n",
    "        \n",
    "    if 'politics' in str(centroid):\n",
    "        politics_cluster.append(str(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectors['sports_centroid'] = tfidf_vectors[sports_cluster].sum(axis=1)\n",
    "tfidf_vectors['food_centroid'] = tfidf_vectors[food_cluster].sum(axis=1)\n",
    "tfidf_vectors['tech_centroid'] = tfidf_vectors[tech_cluster].sum(axis=1)\n",
    "tfidf_vectors['science_centroid'] = tfidf_vectors[science_cluster].sum(axis=1)\n",
    "tfidf_vectors['business_centroid'] = tfidf_vectors[business_cluster].sum(axis=1)\n",
    "tfidf_vectors['politics_centroid'] = tfidf_vectors[politics_cluster].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'business': ['0203_food.txt-tfidf'],\n",
       " 'food': ['0201_food.txt-tfidf'],\n",
       " 'politics': ['0105_food.txt-tfidf',\n",
       "  '0101_sports.txt-tfidf',\n",
       "  '0117_sports.txt-tfidf',\n",
       "  '0306_science.txt-tfidf',\n",
       "  '0111_sports.txt-tfidf',\n",
       "  '0502_business.txt-tfidf',\n",
       "  '0202_food.txt-tfidf',\n",
       "  '0114_sports.txt-tfidf',\n",
       "  '0108_sports.txt-tfidf',\n",
       "  '0520_politics.txt-tfidf',\n",
       "  '0116_food.txt-tfidf',\n",
       "  '0302_science.txt-tfidf'],\n",
       " 'science': ['0118_sports.txt-tfidf',\n",
       "  '0518_business.txt-tfidf',\n",
       "  '0515_politics.txt-tfidf',\n",
       "  '0104_sports.txt-tfidf',\n",
       "  '0305_tech.txt-tfidf',\n",
       "  '0310_science.txt-tfidf',\n",
       "  '0109_sports.txt-tfidf',\n",
       "  '0409_science.txt-tfidf',\n",
       "  '0519_business.txt-tfidf',\n",
       "  '0309_science.txt-tfidf',\n",
       "  '0420_tech.txt-tfidf',\n",
       "  '0313_tech.txt-tfidf',\n",
       "  '0312_tech.txt-tfidf',\n",
       "  '0315_science.txt-tfidf',\n",
       "  '0419_science.txt-tfidf',\n",
       "  '0415_tech.txt-tfidf',\n",
       "  '0216_food.txt-tfidf',\n",
       "  '0217_food.txt-tfidf',\n",
       "  '0319_tech.txt-tfidf',\n",
       "  '0318_tech.txt-tfidf',\n",
       "  '0406_science.txt-tfidf',\n",
       "  '0106_sports.txt-tfidf',\n",
       "  '0314_tech.txt-tfidf',\n",
       "  '0303_science.txt-tfidf',\n",
       "  '0506_business.txt-tfidf',\n",
       "  '0501_business.txt-tfidf',\n",
       "  '0211_food.txt-tfidf',\n",
       "  '0514_business.txt-tfidf',\n",
       "  '0120_sports.txt-tfidf',\n",
       "  '0513_business.txt-tfidf',\n",
       "  '0413_science.txt-tfidf',\n",
       "  '0205_sports.txt-tfidf',\n",
       "  '0416_science.txt-tfidf',\n",
       "  '0115_food.txt-tfidf',\n",
       "  '0112_sports.txt-tfidf',\n",
       "  '0512_business.txt-tfidf',\n",
       "  '0405_tech.txt-tfidf',\n",
       "  '0103_sports.txt-tfidf',\n",
       "  '0206_food.txt-tfidf',\n",
       "  '0207_food.txt-tfidf',\n",
       "  '0403_science.txt-tfidf',\n",
       "  '0507_business.txt-tfidf',\n",
       "  '0404_science.txt-tfidf',\n",
       "  '0214_food.txt-tfidf',\n",
       "  '0418_science.txt-tfidf',\n",
       "  '0301_science.txt-tfidf',\n",
       "  '0517_business.txt-tfidf',\n",
       "  '0220_sports.txt-tfidf',\n",
       "  '0308_science.txt-tfidf',\n",
       "  '0411_science.txt-tfidf',\n",
       "  '0311_tech.txt-tfidf',\n",
       "  '0408_science.txt-tfidf',\n",
       "  '0119_sports.txt-tfidf',\n",
       "  '0414_science.txt-tfidf',\n",
       "  '0401_science.txt-tfidf',\n",
       "  '0503_business.txt-tfidf',\n",
       "  '0208_food.txt-tfidf',\n",
       "  '0209_food.txt-tfidf',\n",
       "  '0504_business.txt-tfidf',\n",
       "  '0110_food.txt-tfidf',\n",
       "  '0511_business.txt-tfidf',\n",
       "  '0304_science.txt-tfidf',\n",
       "  '0516_business.txt-tfidf',\n",
       "  '0307_science.txt-tfidf',\n",
       "  '0113_sports.txt-tfidf',\n",
       "  '0509_business.txt-tfidf',\n",
       "  '0402_science.txt-tfidf',\n",
       "  '0417_science.txt-tfidf',\n",
       "  '0102_sports.txt-tfidf',\n",
       "  '0320_science.txt-tfidf',\n",
       "  '0215_sports.txt-tfidf',\n",
       "  '0107_sports.txt-tfidf',\n",
       "  '0505_politics.txt-tfidf',\n",
       "  '0212_food.txt-tfidf',\n",
       "  '0213_food.txt-tfidf',\n",
       "  '0412_science.txt-tfidf',\n",
       "  '0508_business.txt-tfidf',\n",
       "  '0410_tech.txt-tfidf',\n",
       "  '0510_politics.txt-tfidf',\n",
       "  '0210_sports.txt-tfidf',\n",
       "  '0218_food.txt-tfidf',\n",
       "  '0219_food.txt-tfidf',\n",
       "  '0317_tech.txt-tfidf',\n",
       "  '0316_tech.txt-tfidf',\n",
       "  '0407_science.txt-tfidf'],\n",
       " 'sports': ['idf'],\n",
       " 'tech': ['0204_food.txt-tfidf']}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "import warnings\n",
    "\n",
    "# Ignore FutureWarnings, there is a function call within the sklearn library that is using an outdated pandas method (I think)\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "#Load the data from the Excel file\n",
    "data = pd.read_excel(\"tdf-vectors.xlsx\")\n",
    "\n",
    "# Transpose the data so that documents are rows and words are columns\n",
    "transposed_data = data.set_index(\"Unnamed: 0\").transpose()\n",
    "\n",
    "# Specify the centroid document names and extract their TF-IDF vectors\n",
    "centroid_names = [\n",
    "    \"9901_sports.txt-tfidf\", \n",
    "    \"9902_food.txt-tfidf\", \n",
    "    \"9903_tech.txt-tfidf\", \n",
    "    \"9904_science.txt-tfidf\", \n",
    "    \"9905_business.txt-tfidf\", \n",
    "    \"9906_politics.txt-tfidf\"\n",
    "]\n",
    "centroids = transposed_data.loc[centroid_names]\n",
    "\n",
    "# Prepare the data for clustering (excluding the centroids themselves)\n",
    "data_for_clustering = transposed_data.drop(centroid_names)\n",
    "\n",
    "# Initialize KMeans with the specified centroids and fit the model to the data\n",
    "kmeans = KMeans(n_clusters=6, init=centroids, n_init=1)\n",
    "labels = kmeans.fit_predict(data_for_clustering)\n",
    "\n",
    "# Add the cluster labels to the dataset\n",
    "data_for_clustering['Cluster'] = labels\n",
    "\n",
    "# Create a mapping from cluster number to cluster name\n",
    "cluster_mapping = {\n",
    "    0: \"sports\",\n",
    "    1: \"food\",\n",
    "    2: \"tech\",\n",
    "    3: \"science\",\n",
    "    4: \"business\",\n",
    "    5: \"politics\"\n",
    "}\n",
    "\n",
    "#  Replace cluster numbers with names in the dataframe\n",
    "data_for_clustering['Cluster'] = data_for_clustering['Cluster'].map(cluster_mapping)\n",
    "\n",
    "# Create a simplified dataframe showing the document and its cluster\n",
    "document_clusters = data_for_clustering[['Cluster']].reset_index()\n",
    "document_clusters.columns = ['Document', 'Cluster']\n",
    "\n",
    "# At this point, 'document_clusters' contains the documents with their respective cluster names.\n",
    "\n",
    "# Group by 'Cluster' and create a dictionary where keys are cluster names and values are lists of documents\n",
    "clustered_documents = {}\n",
    "for cluster, group in document_clusters.groupby('Cluster'):\n",
    "    clustered_documents[cluster] = list(group['Document'])\n",
    "\n",
    "# Display documents for each cluster (for demonstration, we'll show the first few documents in each cluster)\n",
    "clustered_document_samples = {cluster: docs for cluster, docs in clustered_documents.items()}\n",
    "clustered_document_samples"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
